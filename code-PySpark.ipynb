{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyAM6jU5-ndG",
        "outputId": "665ef536-4e1c-403a-8bc6-90cbea2ad665"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPHlYRoQ--qx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4c0ce02b-0a9d-4e35-b66a-e4e74b0df8e4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/spark-3.2.1-bin-hadoop2.7'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q https://archive.apache.org/dist/spark/spark-3.2.1/spark-3.2.1-bin-hadoop2.7.tgz\n",
        "!tar xf spark-3.2.1-bin-hadoop2.7.tgz\n",
        "!pip install -q findspark\n",
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop2.7\"\n",
        "import findspark\n",
        "findspark.init()\n",
        "findspark.find()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuDyVtEA_WSa"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import numpy as np\n",
        "# !pip install --upgrade pyspark==3.1.1\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.getOrCreate()\n",
        "\n",
        "from pyspark.sql.functions import col, countDistinct\n",
        "from pyspark.sql.functions import year, last, count, isnan, when, col, isnull\n",
        "from pyspark.sql.functions import to_date, from_unixtime\n",
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.window import Window\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from pyspark.ml.stat import Correlation\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "from pyspark.sql import Window"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIul6Dla_uEX"
      },
      "outputs": [],
      "source": [
        "df1 = spark.read.option(\"header\",True) \\\n",
        "     .csv(\"/content/drive/MyDrive/big data imbd/big-data-course-2022-projects-master/imdb/train-1.csv\")\n",
        "\n",
        "df2 = spark.read.option(\"header\",True) \\\n",
        "     .csv(\"/content/drive/MyDrive/big data imbd/big-data-course-2022-projects-master/imdb/train-2.csv\")\n",
        "\n",
        "df3 = spark.read.option(\"header\",True) \\\n",
        "     .csv(\"/content/drive/MyDrive/big data imbd/big-data-course-2022-projects-master/imdb/train-3.csv\")\n",
        "\n",
        "df4 = spark.read.option(\"header\",True) \\\n",
        "     .csv(\"/content/drive/MyDrive/big data imbd/big-data-course-2022-projects-master/imdb/train-4.csv\")\n",
        "df5 = spark.read.option(\"header\",True) \\\n",
        "     .csv(\"/content/drive/MyDrive/big data imbd/big-data-course-2022-projects-master/imdb/train-5.csv\")\n",
        "df6 = spark.read.option(\"header\",True) \\\n",
        "     .csv(\"/content/drive/MyDrive/big data imbd/big-data-course-2022-projects-master/imdb/train-6.csv\")\n",
        "\n",
        "df7 = spark.read.option(\"header\",True) \\\n",
        "     .csv(\"/content/drive/MyDrive/big data imbd/big-data-course-2022-projects-master/imdb/train-7.csv\")\n",
        "\n",
        "df8 = spark.read.option(\"header\",True) \\\n",
        "     .csv(\"/content/drive/MyDrive/big data imbd/big-data-course-2022-projects-master/imdb/train-8.csv\")\n",
        "\n",
        "df_val  = spark.read.option(\"header\",True) \\\n",
        "     .csv(\"/content/drive/MyDrive/big data imbd/big-data-course-2022-projects-master/imdb/validation_hidden.csv\")\n",
        "\n",
        "df_test  = spark.read.option(\"header\",True) \\\n",
        "     .csv(\"/content/drive/MyDrive/big data imbd/big-data-course-2022-projects-master/imdb/test_hidden.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Nieuwe sectie"
      ],
      "metadata": {
        "id": "YsaRDIJxaimD"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VN5k3XAPAYe7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c37047a7-8c30-41c1-8374-2ee3bba5eba3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------+--------------------+--------------------+---------+-------+--------------+--------+-----+\n",
            "|_c0|   tconst|        primaryTitle|       originalTitle|startYear|endYear|runtimeMinutes|numVotes|label|\n",
            "+---+---------+--------------------+--------------------+---------+-------+--------------+--------+-----+\n",
            "|  4|tt0010600|            The Doll|           Die Puppe|     1919|     \\N|            66|  1898.0| True|\n",
            "|  7|tt0011841|       Way Down East|       Way Down East|     1920|     \\N|           145|  5376.0| True|\n",
            "|  9|tt0012494|             Déstiny|        Der müde Tod|     1921|     \\N|            97|  5842.0| True|\n",
            "| 25|tt0015163|       The Navigator|       The Navigator|     1924|     \\N|            59|  9652.0| True|\n",
            "| 38|tt0016220|The Phantom of th...|The Phantom of th...|     1925|     \\N|            93| 17887.0| True|\n",
            "| 42|tt0016630|     Báttling Bútlér|     Battling Butler|     1926|     \\N|            77|  3285.0| True|\n",
            "| 81|tt0021015|Juno and the Paycock|                null|     1929|     \\N|            85|  2275.0|False|\n",
            "|118|tt0023973|Thé Éáglé ánd thé...|                null|     1933|     \\N|            73|    null| True|\n",
            "|119|tt0023986| Émplớyéés' Éntráncé|                null|     1933|     \\N|            75|    null| True|\n",
            "|123|tt0024184|   The Invisible Man|   The Invisible Man|     1933|     \\N|            71| 33562.0| True|\n",
            "|125|tt0024216|           King Kong|           King Kong|     1933|     \\N|           100| 83177.0| True|\n",
            "|135|tt0025028|               Dames|                null|     1934|     \\N|            91|  2038.0| True|\n",
            "|163|tt0027478|The Crime of Mons...|Le crime de Monsi...|     1936|     \\N|            80|    null| True|\n",
            "|180|tt0028333|          Swing Timé|                null|     1936|     \\N|           103|    null| True|\n",
            "|215|tt0030341|   The Lady Vanishes|   The Lady Vanishes|     1938|     \\N|            96| 50707.0| True|\n",
            "|222|tt0031143|The Cat and the C...|                null|     1939|     \\N|            72|  2967.0| True|\n",
            "|231|tt0031385|  Goodbye, Mr. Chips|                null|     1939|     \\N|           114| 10311.0| True|\n",
            "|239|tt0031647|            Midnight|                null|     1939|     \\N|            94|  4904.0| True|\n",
            "|242|tt0031762|Only Angels Have ...|                null|     1939|     \\N|           121| 13595.0| True|\n",
            "|253|tt0032156|The Story of the ...|  Zangiku monogatari|     1939|     \\N|           143|  3600.0| True|\n",
            "+---+---------+--------------------+--------------------+---------+-------+--------------+--------+-----+\n",
            "only showing top 20 rows\n",
            "\n",
            "Number of entries in df_count: 7959\n"
          ]
        }
      ],
      "source": [
        "from functools import reduce\n",
        "\n",
        "# union all dataframes into a single dataframe\n",
        "dfs = [df1, df2, df3, df4, df5, df6, df7, df8]\n",
        "df_all = reduce(lambda df1, df2: df1.union(df2), dfs)\n",
        "\n",
        "df_all.show()\n",
        "count = df_all.count()\n",
        "print(\"Number of entries in df_count:\", count)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5vjnAyi_EM-W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6199241e-8893-4cb2-e436-7795fde52746"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+------------+-------------+---------+-------+--------------+--------+-----+\n",
            "|_c0|tconst|primaryTitle|originalTitle|startYear|endYear|runtimeMinutes|numVotes|label|\n",
            "+---+------+------------+-------------+---------+-------+--------------+--------+-----+\n",
            "|  0|     0|           0|         3988|      786|   7173|            13|     790|    0|\n",
            "+---+------+------------+-------------+---------+-------+--------------+--------+-----+\n",
            "\n",
            "+---+------+------------+-------------+---------+-------+--------------+--------+\n",
            "|_c0|tconst|primaryTitle|originalTitle|startYear|endYear|runtimeMinutes|numVotes|\n",
            "+---+------+------------+-------------+---------+-------+--------------+--------+\n",
            "|  0|     0|           0|          468|       94|    861|             2|      91|\n",
            "+---+------+------------+-------------+---------+-------+--------------+--------+\n",
            "\n",
            "+---+------+------------+-------------+---------+-------+--------------+--------+\n",
            "|_c0|tconst|primaryTitle|originalTitle|startYear|endYear|runtimeMinutes|numVotes|\n",
            "+---+------+------------+-------------+---------+-------+--------------+--------+\n",
            "|  0|     0|           0|          544|      120|    966|             1|     119|\n",
            "+---+------+------------+-------------+---------+-------+--------------+--------+\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql.functions import col, count, isnan, when\n",
        "\n",
        "# recognize \"\\N\" as Null\n",
        "df_all = df_all.select([when(col(c)==\"\\\\N\",None).otherwise(col(c)).alias(c) for c in df_all.columns])\n",
        "df_val = df_val.select([when(col(c)==\"\\\\N\",None).otherwise(col(c)).alias(c) for c in df_val.columns])\n",
        "df_test = df_test.select([when(col(c)==\"\\\\N\",None).otherwise(col(c)).alias(c) for c in df_test.columns])\n",
        "\n",
        "# count the number of missing values in each column\n",
        "missing_values_all = df_all.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_all.columns])\n",
        "missing_values_val = df_val.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_val.columns])\n",
        "missing_values_test = df_test.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_test.columns])\n",
        "\n",
        "\n",
        "# display the results\n",
        "missing_values_all.show()\n",
        "missing_values_val.show()\n",
        "missing_values_test.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j6xFAXjOHXPI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29826f4d-59c2-4efd-d006-9e9c86e0e6c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark==3.1.1 in /usr/local/lib/python3.9/dist-packages (3.1.1)\n",
            "Requirement already satisfied: py4j==0.10.9 in /usr/local/lib/python3.9/dist-packages (from pyspark==3.1.1) (0.10.9)\n"
          ]
        }
      ],
      "source": [
        "# !pip install --upgrade pyspark==3.1.1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJR9x6xDGTJi"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql.functions import col\n",
        "from pyspark.sql import functions as F\n",
        "import pandas as pd\n",
        "from pyspark.sql.functions import *\n",
        "\n",
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, lit\n",
        "from pyspark.sql.types import StructType, StructField, StringType,IntegerType\n",
        "\n",
        "##Function that removes accent\n",
        "@F.pandas_udf('string')\n",
        "def strip_accents(s: pd.Series) -> pd.Series:\n",
        "    return s.str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Fixing the titles and years\n",
        "# Stripping accents\n",
        "df_all = df_all.withColumn('primaryTitle', strip_accents('primaryTitle')).withColumn('originalTitle', strip_accents('originalTitle'))\n",
        "df_val = df_val.withColumn('primaryTitle', strip_accents('primaryTitle')).withColumn('originalTitle', strip_accents('originalTitle'))\n",
        "df_test = df_test.withColumn('primaryTitle', strip_accents('primaryTitle')).withColumn('originalTitle', strip_accents('originalTitle'))\n",
        "\n",
        "# Copy the primaryTitle to the missing values of originalTitles, also copying the years\n",
        "df_all = df_all.withColumn(\"originalTitle\", coalesce(df_all[\"originalTitle\"],df_all[\"primaryTitle\"])).withColumn(\"endYear\", coalesce(df_all[\"startYear\"], df_all[\"endYear\"])).drop(\"startYear\")\n",
        "df_val = df_val.withColumn(\"originalTitle\", coalesce(df_val[\"originalTitle\"],df_val[\"primaryTitle\"])).withColumn(\"endYear\", coalesce(df_val[\"startYear\"], df_val[\"endYear\"])).drop(\"startYear\")\n",
        "df_test = df_test.withColumn(\"originalTitle\", coalesce(df_test[\"originalTitle\"],df_test[\"primaryTitle\"])).withColumn(\"endYear\", coalesce(df_test[\"startYear\"], df_test[\"endYear\"])).drop(\"startYear\")\n",
        "\n",
        "df_all.show()\n",
        "df_val.show()\n",
        "df_test.show()"
      ],
      "metadata": {
        "id": "Nj8nfUwNOoV-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6ced9321-09bd-4715-c7e8-7d7ce24d4ade"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------+--------------------+--------------------+-------+--------------+--------+-----+\n",
            "|_c0|   tconst|        primaryTitle|       originalTitle|endYear|runtimeMinutes|numVotes|label|\n",
            "+---+---------+--------------------+--------------------+-------+--------------+--------+-----+\n",
            "|  4|tt0010600|            The Doll|           Die Puppe|   1919|            66|  1898.0| True|\n",
            "|  7|tt0011841|       Way Down East|       Way Down East|   1920|           145|  5376.0| True|\n",
            "|  9|tt0012494|             Destiny|        Der mude Tod|   1921|            97|  5842.0| True|\n",
            "| 25|tt0015163|       The Navigator|       The Navigator|   1924|            59|  9652.0| True|\n",
            "| 38|tt0016220|The Phantom of th...|The Phantom of th...|   1925|            93| 17887.0| True|\n",
            "| 42|tt0016630|     Battling Butler|     Battling Butler|   1926|            77|  3285.0| True|\n",
            "| 81|tt0021015|Juno and the Paycock|Juno and the Paycock|   1929|            85|  2275.0|False|\n",
            "|118|tt0023973|The Eagle and the...|The Eagle and the...|   1933|            73|    null| True|\n",
            "|119|tt0023986| Employees' Entrance| Employees' Entrance|   1933|            75|    null| True|\n",
            "|123|tt0024184|   The Invisible Man|   The Invisible Man|   1933|            71| 33562.0| True|\n",
            "|125|tt0024216|           King Kong|           King Kong|   1933|           100| 83177.0| True|\n",
            "|135|tt0025028|               Dames|               Dames|   1934|            91|  2038.0| True|\n",
            "|163|tt0027478|The Crime of Mons...|Le crime de Monsi...|   1936|            80|    null| True|\n",
            "|180|tt0028333|          Swing Time|          Swing Time|   1936|           103|    null| True|\n",
            "|215|tt0030341|   The Lady Vanishes|   The Lady Vanishes|   1938|            96| 50707.0| True|\n",
            "|222|tt0031143|The Cat and the C...|The Cat and the C...|   1939|            72|  2967.0| True|\n",
            "|231|tt0031385|  Goodbye, Mr. Chips|  Goodbye, Mr. Chips|   1939|           114| 10311.0| True|\n",
            "|239|tt0031647|            Midnight|            Midnight|   1939|            94|  4904.0| True|\n",
            "|242|tt0031762|Only Angels Have ...|Only Angels Have ...|   1939|           121| 13595.0| True|\n",
            "|253|tt0032156|The Story of the ...|  Zangiku monogatari|   1939|           143|  3600.0| True|\n",
            "+---+---------+--------------------+--------------------+-------+--------------+--------+-----+\n",
            "only showing top 20 rows\n",
            "\n",
            "+---+---------+--------------------+--------------------+-------+--------------+--------+\n",
            "|_c0|   tconst|        primaryTitle|       originalTitle|endYear|runtimeMinutes|numVotes|\n",
            "+---+---------+--------------------+--------------------+-------+--------------+--------+\n",
            "|  0|tt0003740|             Cabiria|             Cabiria|   1914|           148|  3452.0|\n",
            "|  1|tt0008663|     A Man There Was|         Terje Vigen|   1917|            65|  1882.0|\n",
            "|  3|tt0010307|           J'accuse!|           J'accuse!|   1919|           166|  1692.0|\n",
            "| 18|tt0014429|        Safety Last!|        Safety Last!|   1923|            74| 19898.0|\n",
            "| 27|tt0015175|Die Nibelungen: S...|Die Nibelungen: S...|   1924|           143|  5676.0|\n",
            "| 39|tt0016332|       Seven Chances|       Seven Chances|   1925|            56|  9914.0|\n",
            "| 61|tt0018737|       Pandora's Box|       Pandora's Box|   1929|           109| 10475.0|\n",
            "| 65|tt0018839|The Docks of New ...|The Docks of New ...|   1928|            76|  4339.0|\n",
            "| 71|tt0019421| Steamboat Bill, Jr.| Steamboat Bill, Jr.|   1928|            70| 14166.0|\n",
            "| 75|tt0019901|   Woman in the Moon|   Woman in the Moon|   1929|           156|    null|\n",
            "| 91|tt0022150|          Le Million|          Le Million|   1931|            91|  3434.0|\n",
            "| 92|tt0022153|   The Miracle Woman|   The Miracle Woman|   1931|            90|  2013.0|\n",
            "|142|tt0025699|   Randy Rides Alone|   Randy Rides Alone|   1934|            52|  1034.0|\n",
            "|153|tt0026725|      Les Miserables|      Les Miserables|   1935|           108|  3512.0|\n",
            "|158|tt0027336|    The Lower Depths|       Les bas-fonds|   1936|            95|  3194.0|\n",
            "|159|tt0027342|      They Were Five|     La belle equipe|   1936|           100|  1202.0|\n",
            "|167|tt0027672| Sisters of the Gion| Sisters of the Gion|   1936|            69|  2621.0|\n",
            "|174|tt0028167|           Rembrandt|           Rembrandt|   1936|            85|  1778.0|\n",
            "|178|tt0028313|The Story of Loui...|The Story of Loui...|   1936|            86|  2705.0|\n",
            "|187|tt0028737|          Confession|          Confession|   1937|            87|  1201.0|\n",
            "+---+---------+--------------------+--------------------+-------+--------------+--------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+---+---------+--------------------+--------------------+-------+--------------+--------+\n",
            "|_c0|   tconst|        primaryTitle|       originalTitle|endYear|runtimeMinutes|numVotes|\n",
            "+---+---------+--------------------+--------------------+-------+--------------+--------+\n",
            "| 22|tt0014972| He Who Gets Slapped| He Who Gets Slapped|   1924|            95|  3654.0|\n",
            "| 23|tt0015016|      The Iron Horse|      The Iron Horse|   1924|           150|  2136.0|\n",
            "| 26|tt0015174|Die Nibelungen: K...|Die Nibelungen: K...|   1924|           129|  4341.0|\n",
            "| 28|tt0015214|             At 3:25|             At 3:25|   1925|            59|  1724.0|\n",
            "| 34|tt0015863|             Go West|             Go West|   1925|            69|  4188.0|\n",
            "| 40|tt0016481|             Variety|             Variete|   1925|           104|  1188.0|\n",
            "| 46|tt0017136|          Metropolis|          Metropolis|   1927|           153|168372.0|\n",
            "| 66|tt0018876|   The Farmer's Wife|   The Farmer's Wife|   1928|           100|  2741.0|\n",
            "| 67|tt0019074| Laugh, Clown, Laugh| Laugh, Clown, Laugh|   1928|            73|  1934.0|\n",
            "| 84|tt0021730|           The Champ|           The Champ|   1931|            86|  3057.0|\n",
            "| 87|tt0022074|The Smiling Lieut...|The Smiling Lieut...|   1931|            93|  3632.0|\n",
            "| 88|tt0022080|               Limit|               Limit|   1931|           114|    null|\n",
            "|103|tt0023241|         Movie Crazy|         Movie Crazy|   1932|            84|    null|\n",
            "|111|tt0023775|           Baby Face|           Baby Face|   1933|            71|  6775.0|\n",
            "|115|tt0023940|   Design for Living|   Design for Living|   1933|            91|    null|\n",
            "|120|tt0024028|    Footlight Parade|    Footlight Parade|   1933|           104|  5285.0|\n",
            "|126|tt0024240|      Lady for a Day|      Lady for a Day|   1933|            96|    null|\n",
            "|143|tt0025746| The Scarlet Empress| The Scarlet Empress|   1934|           104|  6400.0|\n",
            "|144|tt0025862| Tarzan and His Mate| Tarzan and His Mate|   1934|           104|  5033.0|\n",
            "|147|tt0025929|A Story of Floati...|  Ukikusa monogatari|   1934|            86|  3032.0|\n",
            "+---+---------+--------------------+--------------------+-------+--------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import IntegerType, BooleanType\n",
        "df_all = df_all.withColumn('runtimeMinutes',df_all['runtimeMinutes'].cast(IntegerType())).withColumn('numVotes',df_all['numVotes'].cast(IntegerType()))\n",
        "for col in df_all.dtypes:\n",
        "    print(col[0]+\" , \"+col[1])\n",
        "\n",
        "df_val = df_val.withColumn('runtimeMinutes',df_val['runtimeMinutes'].cast(IntegerType())).withColumn('numVotes',df_val['numVotes'].cast(IntegerType()))\n",
        "for col in df_val.dtypes:\n",
        "    print(col[0]+\" , \"+col[1])\n",
        "\n",
        "df_test = df_test.withColumn('runtimeMinutes',df_test['runtimeMinutes'].cast(IntegerType())).withColumn('numVotes',df_test['numVotes'].cast(IntegerType()))\n",
        "for col in df_test.dtypes:\n",
        "    print(col[0]+\" , \"+col[1])"
      ],
      "metadata": {
        "id": "yHIJm3QRBewA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32a5fff5-8ecc-443e-b142-04a09371b252"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "_c0 , string\n",
            "tconst , string\n",
            "primaryTitle , string\n",
            "originalTitle , string\n",
            "endYear , string\n",
            "runtimeMinutes , int\n",
            "numVotes , int\n",
            "label , string\n",
            "_c0 , string\n",
            "tconst , string\n",
            "primaryTitle , string\n",
            "originalTitle , string\n",
            "endYear , string\n",
            "runtimeMinutes , int\n",
            "numVotes , int\n",
            "_c0 , string\n",
            "tconst , string\n",
            "primaryTitle , string\n",
            "originalTitle , string\n",
            "endYear , string\n",
            "runtimeMinutes , int\n",
            "numVotes , int\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e292e45-ef55-4c0a-943b-6cdfdd1da0ac",
        "id": "t3Tebu1NR2t_"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------+--------------------+--------------------+-------+--------------+--------+-----+\n",
            "|_c0|   tconst|        primaryTitle|       originalTitle|endYear|runtimeMinutes|numVotes|label|\n",
            "+---+---------+--------------------+--------------------+-------+--------------+--------+-----+\n",
            "|  4|tt0010600|            The Doll|           Die Puppe|   1919|            66|    1898| True|\n",
            "|  7|tt0011841|       Way Down East|       Way Down East|   1920|           145|    5376| True|\n",
            "|  9|tt0012494|             Destiny|        Der mude Tod|   1921|            97|    5842| True|\n",
            "| 25|tt0015163|       The Navigator|       The Navigator|   1924|            59|    9652| True|\n",
            "| 38|tt0016220|The Phantom of th...|The Phantom of th...|   1925|            93|   17887| True|\n",
            "| 42|tt0016630|     Battling Butler|     Battling Butler|   1926|            77|    3285| True|\n",
            "| 81|tt0021015|Juno and the Paycock|Juno and the Paycock|   1929|            85|    2275|False|\n",
            "|118|tt0023973|The Eagle and the...|The Eagle and the...|   1933|            73|    2841| True|\n",
            "|119|tt0023986| Employees' Entrance| Employees' Entrance|   1933|            75|    2841| True|\n",
            "|123|tt0024184|   The Invisible Man|   The Invisible Man|   1933|            71|   33562| True|\n",
            "|125|tt0024216|           King Kong|           King Kong|   1933|           100|   83177| True|\n",
            "|135|tt0025028|               Dames|               Dames|   1934|            91|    2038| True|\n",
            "|163|tt0027478|The Crime of Mons...|Le crime de Monsi...|   1936|            80|    2841| True|\n",
            "|180|tt0028333|          Swing Time|          Swing Time|   1936|           103|    2841| True|\n",
            "|215|tt0030341|   The Lady Vanishes|   The Lady Vanishes|   1938|            96|   50707| True|\n",
            "|222|tt0031143|The Cat and the C...|The Cat and the C...|   1939|            72|    2967| True|\n",
            "|231|tt0031385|  Goodbye, Mr. Chips|  Goodbye, Mr. Chips|   1939|           114|   10311| True|\n",
            "|239|tt0031647|            Midnight|            Midnight|   1939|            94|    4904| True|\n",
            "|242|tt0031762|Only Angels Have ...|Only Angels Have ...|   1939|           121|   13595| True|\n",
            "|253|tt0032156|The Story of the ...|  Zangiku monogatari|   1939|           143|    3600| True|\n",
            "+---+---------+--------------------+--------------------+-------+--------------+--------+-----+\n",
            "only showing top 20 rows\n",
            "\n",
            "+---+---------+--------------------+--------------------+-------+--------------+--------+\n",
            "|_c0|   tconst|        primaryTitle|       originalTitle|endYear|runtimeMinutes|numVotes|\n",
            "+---+---------+--------------------+--------------------+-------+--------------+--------+\n",
            "|  0|tt0003740|             Cabiria|             Cabiria|   1914|           148|    3452|\n",
            "|  1|tt0008663|     A Man There Was|         Terje Vigen|   1917|            65|    1882|\n",
            "|  3|tt0010307|           J'accuse!|           J'accuse!|   1919|           166|    1692|\n",
            "| 18|tt0014429|        Safety Last!|        Safety Last!|   1923|            74|   19898|\n",
            "| 27|tt0015175|Die Nibelungen: S...|Die Nibelungen: S...|   1924|           143|    5676|\n",
            "| 39|tt0016332|       Seven Chances|       Seven Chances|   1925|            56|    9914|\n",
            "| 61|tt0018737|       Pandora's Box|       Pandora's Box|   1929|           109|   10475|\n",
            "| 65|tt0018839|The Docks of New ...|The Docks of New ...|   1928|            76|    4339|\n",
            "| 71|tt0019421| Steamboat Bill, Jr.| Steamboat Bill, Jr.|   1928|            70|   14166|\n",
            "| 75|tt0019901|   Woman in the Moon|   Woman in the Moon|   1929|           156|    2592|\n",
            "| 91|tt0022150|          Le Million|          Le Million|   1931|            91|    3434|\n",
            "| 92|tt0022153|   The Miracle Woman|   The Miracle Woman|   1931|            90|    2013|\n",
            "|142|tt0025699|   Randy Rides Alone|   Randy Rides Alone|   1934|            52|    1034|\n",
            "|153|tt0026725|      Les Miserables|      Les Miserables|   1935|           108|    3512|\n",
            "|158|tt0027336|    The Lower Depths|       Les bas-fonds|   1936|            95|    3194|\n",
            "|159|tt0027342|      They Were Five|     La belle equipe|   1936|           100|    1202|\n",
            "|167|tt0027672| Sisters of the Gion| Sisters of the Gion|   1936|            69|    2621|\n",
            "|174|tt0028167|           Rembrandt|           Rembrandt|   1936|            85|    1778|\n",
            "|178|tt0028313|The Story of Loui...|The Story of Loui...|   1936|            86|    2705|\n",
            "|187|tt0028737|          Confession|          Confession|   1937|            87|    1201|\n",
            "+---+---------+--------------------+--------------------+-------+--------------+--------+\n",
            "only showing top 20 rows\n",
            "\n",
            "+---+---------+--------------------+--------------------+-------+--------------+--------+\n",
            "|_c0|   tconst|        primaryTitle|       originalTitle|endYear|runtimeMinutes|numVotes|\n",
            "+---+---------+--------------------+--------------------+-------+--------------+--------+\n",
            "| 22|tt0014972| He Who Gets Slapped| He Who Gets Slapped|   1924|            95|    3654|\n",
            "| 23|tt0015016|      The Iron Horse|      The Iron Horse|   1924|           150|    2136|\n",
            "| 26|tt0015174|Die Nibelungen: K...|Die Nibelungen: K...|   1924|           129|    4341|\n",
            "| 28|tt0015214|             At 3:25|             At 3:25|   1925|            59|    1724|\n",
            "| 34|tt0015863|             Go West|             Go West|   1925|            69|    4188|\n",
            "| 40|tt0016481|             Variety|             Variete|   1925|           104|    1188|\n",
            "| 46|tt0017136|          Metropolis|          Metropolis|   1927|           153|  168372|\n",
            "| 66|tt0018876|   The Farmer's Wife|   The Farmer's Wife|   1928|           100|    2741|\n",
            "| 67|tt0019074| Laugh, Clown, Laugh| Laugh, Clown, Laugh|   1928|            73|    1934|\n",
            "| 84|tt0021730|           The Champ|           The Champ|   1931|            86|    3057|\n",
            "| 87|tt0022074|The Smiling Lieut...|The Smiling Lieut...|   1931|            93|    3632|\n",
            "| 88|tt0022080|               Limit|               Limit|   1931|           114|    2555|\n",
            "|103|tt0023241|         Movie Crazy|         Movie Crazy|   1932|            84|    2555|\n",
            "|111|tt0023775|           Baby Face|           Baby Face|   1933|            71|    6775|\n",
            "|115|tt0023940|   Design for Living|   Design for Living|   1933|            91|    2555|\n",
            "|120|tt0024028|    Footlight Parade|    Footlight Parade|   1933|           104|    5285|\n",
            "|126|tt0024240|      Lady for a Day|      Lady for a Day|   1933|            96|    2555|\n",
            "|143|tt0025746| The Scarlet Empress| The Scarlet Empress|   1934|           104|    6400|\n",
            "|144|tt0025862| Tarzan and His Mate| Tarzan and His Mate|   1934|           104|    5033|\n",
            "|147|tt0025929|A Story of Floati...|  Ukikusa monogatari|   1934|            86|    3032|\n",
            "+---+---------+--------------------+--------------------+-------+--------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Fixing the null in numVotes and runtimeMinutes\n",
        "# Replace missing values with median in the runtime and numVotes column\n",
        "\n",
        "all_runtime_med = df_all.approxQuantile('runtimeMinutes',[0.5],0.1)[0]\n",
        "all_numvotes_med = df_all.approxQuantile('numVotes',[0.5],0.1)[0]\n",
        "df_all = df_all.na.fill(all_runtime_med, subset=['runtimeMinutes']).na.fill(all_numvotes_med, subset=['numVotes'])\n",
        "\n",
        "val_runtime_med = df_val.approxQuantile('runtimeMinutes',[0.5],0.1)[0]\n",
        "val_numvotes_med = df_val.approxQuantile('numVotes',[0.5],0.1)[0]\n",
        "df_val = df_val.na.fill(val_runtime_med, subset=['runtimeMinutes']).na.fill(val_numvotes_med, subset=['numVotes'])\n",
        "\n",
        "test_runtime_med = df_test.approxQuantile('runtimeMinutes',[0.5],0.1)[0]\n",
        "test_numvotes_med = df_test.approxQuantile('numVotes',[0.5],0.1)[0]\n",
        "df_test = df_test.na.fill(test_runtime_med, subset=['runtimeMinutes']).na.fill(test_numvotes_med, subset=['numVotes'])\n",
        "\n",
        "df_all.show()\n",
        "df_val.show()\n",
        "df_test.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col, count, isnan, when\n",
        "\n",
        "# count the number of missing values in each column\n",
        "missing_values_all = df_all.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_all.columns])\n",
        "missing_values_val = df_val.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_val.columns])\n",
        "missing_values_test = df_test.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_test.columns])\n",
        "\n",
        "\n",
        "# display the results\n",
        "missing_values_all.show()\n",
        "missing_values_val.show()\n",
        "missing_values_test.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "a_63s8NXbXuU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dde51bd6-2c5c-4a1d-c801-1068e2c95bee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+------------+-------------+-------+--------------+--------+-----+\n",
            "|_c0|tconst|primaryTitle|originalTitle|endYear|runtimeMinutes|numVotes|label|\n",
            "+---+------+------------+-------------+-------+--------------+--------+-----+\n",
            "|  0|     0|           0|            0|      0|             0|       0|    0|\n",
            "+---+------+------------+-------------+-------+--------------+--------+-----+\n",
            "\n",
            "+---+------+------------+-------------+-------+--------------+--------+\n",
            "|_c0|tconst|primaryTitle|originalTitle|endYear|runtimeMinutes|numVotes|\n",
            "+---+------+------------+-------------+-------+--------------+--------+\n",
            "|  0|     0|           0|            0|      0|             0|       0|\n",
            "+---+------+------------+-------------+-------+--------------+--------+\n",
            "\n",
            "+---+------+------------+-------------+-------+--------------+--------+\n",
            "|_c0|tconst|primaryTitle|originalTitle|endYear|runtimeMinutes|numVotes|\n",
            "+---+------+------------+-------------+-------+--------------+--------+\n",
            "|  0|     0|           0|            0|      0|             0|       0|\n",
            "+---+------+------------+-------------+-------+--------------+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from pyspark.ml.linalg import Vectors\n",
        "\n",
        "# from pyspark.ml.linalg import Vectors\n",
        "\n",
        "# # Convert features column to vector data type\n",
        "# df_all = df_all.withColumn('features_vec', Vectors.dense(df_all.features.values))\n",
        "# df_val = df_val.withColumn('features_vec', Vectors.dense(df_val.features.values))\n",
        "# df_test = df_test.withColumn('features_vec', Vectors.dense(df_test.features.values))\n",
        "\n",
        "\n",
        "# # Cast columns to double data type\n",
        "# df_all = df_all.select([df_all[col].cast('double').alias(col) for col in df_all.columns])\n",
        "# df_val = df_val.select([df_val[col].cast('double').alias(col) for col in df_val.columns])\n",
        "# df_test = df_test.select([df_test[col].cast('double').alias(col) for col in df_test.columns])\n"
      ],
      "metadata": {
        "id": "INQfsAFdrumO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all.where(df_all.label.isNull() | isnan(df_all.label)).count()\n"
      ],
      "metadata": {
        "id": "L4PnUgwS1L4-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1fde93a-2c5d-4478-f294-7f5d0166f1b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_all.show()"
      ],
      "metadata": {
        "id": "0Mxi7CFjParG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "7PCbOnUBi2Z4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "\n",
        "numericCols = ['numVotes','runtimeMinutes']\n",
        "# allCols = ['primaryTitle','originalTitle','endYear','runtimeMinutes','numVotes']\n",
        "assembler = VectorAssembler(inputCols=numericCols, outputCol=\"features\")\n",
        "df_all = assembler.transform(df_all)\n",
        "df_all.show()"
      ],
      "metadata": {
        "id": "ptayubZcRFkU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6ab6bab-5e09-4ebc-83a6-a5824dca453e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------+--------------------+--------------------+-------+--------------+--------+-----+---------------+\n",
            "|_c0|   tconst|        primaryTitle|       originalTitle|endYear|runtimeMinutes|numVotes|label|       features|\n",
            "+---+---------+--------------------+--------------------+-------+--------------+--------+-----+---------------+\n",
            "|  4|tt0010600|            The Doll|           Die Puppe|   1919|            66|    1898| True|  [1898.0,66.0]|\n",
            "|  7|tt0011841|       Way Down East|       Way Down East|   1920|           145|    5376| True| [5376.0,145.0]|\n",
            "|  9|tt0012494|             Destiny|        Der mude Tod|   1921|            97|    5842| True|  [5842.0,97.0]|\n",
            "| 25|tt0015163|       The Navigator|       The Navigator|   1924|            59|    9652| True|  [9652.0,59.0]|\n",
            "| 38|tt0016220|The Phantom of th...|The Phantom of th...|   1925|            93|   17887| True| [17887.0,93.0]|\n",
            "| 42|tt0016630|     Battling Butler|     Battling Butler|   1926|            77|    3285| True|  [3285.0,77.0]|\n",
            "| 81|tt0021015|Juno and the Paycock|Juno and the Paycock|   1929|            85|    2275|False|  [2275.0,85.0]|\n",
            "|118|tt0023973|The Eagle and the...|The Eagle and the...|   1933|            73|    2841| True|  [2841.0,73.0]|\n",
            "|119|tt0023986| Employees' Entrance| Employees' Entrance|   1933|            75|    2841| True|  [2841.0,75.0]|\n",
            "|123|tt0024184|   The Invisible Man|   The Invisible Man|   1933|            71|   33562| True| [33562.0,71.0]|\n",
            "|125|tt0024216|           King Kong|           King Kong|   1933|           100|   83177| True|[83177.0,100.0]|\n",
            "|135|tt0025028|               Dames|               Dames|   1934|            91|    2038| True|  [2038.0,91.0]|\n",
            "|163|tt0027478|The Crime of Mons...|Le crime de Monsi...|   1936|            80|    2841| True|  [2841.0,80.0]|\n",
            "|180|tt0028333|          Swing Time|          Swing Time|   1936|           103|    2841| True| [2841.0,103.0]|\n",
            "|215|tt0030341|   The Lady Vanishes|   The Lady Vanishes|   1938|            96|   50707| True| [50707.0,96.0]|\n",
            "|222|tt0031143|The Cat and the C...|The Cat and the C...|   1939|            72|    2967| True|  [2967.0,72.0]|\n",
            "|231|tt0031385|  Goodbye, Mr. Chips|  Goodbye, Mr. Chips|   1939|           114|   10311| True|[10311.0,114.0]|\n",
            "|239|tt0031647|            Midnight|            Midnight|   1939|            94|    4904| True|  [4904.0,94.0]|\n",
            "|242|tt0031762|Only Angels Have ...|Only Angels Have ...|   1939|           121|   13595| True|[13595.0,121.0]|\n",
            "|253|tt0032156|The Story of the ...|  Zangiku monogatari|   1939|           143|    3600| True| [3600.0,143.0]|\n",
            "+---+---------+--------------------+--------------------+-------+--------------+--------+-----+---------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import StringIndexer\n",
        "\n",
        "label_stringIdx = StringIndexer(inputCol = 'label', outputCol = 'labelIndex')\n",
        "df_all = label_stringIdx.fit(df_all).transform(df_all)\n",
        "df_all.show()"
      ],
      "metadata": {
        "id": "vGvAVKwkRFmz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "737a843a-0d2c-467a-cc72-6ce3e55f68b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+---------+--------------------+--------------------+-------+--------------+--------+-----+---------------+----------+\n",
            "|_c0|   tconst|        primaryTitle|       originalTitle|endYear|runtimeMinutes|numVotes|label|       features|labelIndex|\n",
            "+---+---------+--------------------+--------------------+-------+--------------+--------+-----+---------------+----------+\n",
            "|  4|tt0010600|            The Doll|           Die Puppe|   1919|            66|    1898| True|  [1898.0,66.0]|       0.0|\n",
            "|  7|tt0011841|       Way Down East|       Way Down East|   1920|           145|    5376| True| [5376.0,145.0]|       0.0|\n",
            "|  9|tt0012494|             Destiny|        Der mude Tod|   1921|            97|    5842| True|  [5842.0,97.0]|       0.0|\n",
            "| 25|tt0015163|       The Navigator|       The Navigator|   1924|            59|    9652| True|  [9652.0,59.0]|       0.0|\n",
            "| 38|tt0016220|The Phantom of th...|The Phantom of th...|   1925|            93|   17887| True| [17887.0,93.0]|       0.0|\n",
            "| 42|tt0016630|     Battling Butler|     Battling Butler|   1926|            77|    3285| True|  [3285.0,77.0]|       0.0|\n",
            "| 81|tt0021015|Juno and the Paycock|Juno and the Paycock|   1929|            85|    2275|False|  [2275.0,85.0]|       1.0|\n",
            "|118|tt0023973|The Eagle and the...|The Eagle and the...|   1933|            73|    2841| True|  [2841.0,73.0]|       0.0|\n",
            "|119|tt0023986| Employees' Entrance| Employees' Entrance|   1933|            75|    2841| True|  [2841.0,75.0]|       0.0|\n",
            "|123|tt0024184|   The Invisible Man|   The Invisible Man|   1933|            71|   33562| True| [33562.0,71.0]|       0.0|\n",
            "|125|tt0024216|           King Kong|           King Kong|   1933|           100|   83177| True|[83177.0,100.0]|       0.0|\n",
            "|135|tt0025028|               Dames|               Dames|   1934|            91|    2038| True|  [2038.0,91.0]|       0.0|\n",
            "|163|tt0027478|The Crime of Mons...|Le crime de Monsi...|   1936|            80|    2841| True|  [2841.0,80.0]|       0.0|\n",
            "|180|tt0028333|          Swing Time|          Swing Time|   1936|           103|    2841| True| [2841.0,103.0]|       0.0|\n",
            "|215|tt0030341|   The Lady Vanishes|   The Lady Vanishes|   1938|            96|   50707| True| [50707.0,96.0]|       0.0|\n",
            "|222|tt0031143|The Cat and the C...|The Cat and the C...|   1939|            72|    2967| True|  [2967.0,72.0]|       0.0|\n",
            "|231|tt0031385|  Goodbye, Mr. Chips|  Goodbye, Mr. Chips|   1939|           114|   10311| True|[10311.0,114.0]|       0.0|\n",
            "|239|tt0031647|            Midnight|            Midnight|   1939|            94|    4904| True|  [4904.0,94.0]|       0.0|\n",
            "|242|tt0031762|Only Angels Have ...|Only Angels Have ...|   1939|           121|   13595| True|[13595.0,121.0]|       0.0|\n",
            "|253|tt0032156|The Story of the ...|  Zangiku monogatari|   1939|           143|    3600| True| [3600.0,143.0]|       0.0|\n",
            "+---+---------+--------------------+--------------------+-------+--------------+--------+-----+---------------+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train,test = df_all.randomSplit([0.7, 0.3], seed = 2018)\n",
        "print(\"Training Dataset Count: \" + str(train.count()))\n",
        "print(\"Test Dataset Count: \" + str(test.count()))"
      ],
      "metadata": {
        "id": "6YvBuPkRRFpQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f21d76c-db81-44fd-96d9-41ac9410ea13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training Dataset Count: 5611\n",
            "Test Dataset Count: 2348\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "\n",
        "rf = RandomForestClassifier(featuresCol = 'features', labelCol = 'labelIndex')\n",
        "rfModel = rf.fit(train)\n",
        "predictions = rfModel.transform(test)\n",
        "predictions.select('numVotes','runtimeMinutes').show(25)"
      ],
      "metadata": {
        "id": "zL9-bWJcRFr0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59ec25e5-36a2-418c-dac7-c89c43224c51"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+--------------+\n",
            "|numVotes|runtimeMinutes|\n",
            "+--------+--------------+\n",
            "|    2705|            65|\n",
            "|    1444|            84|\n",
            "|    2728|           111|\n",
            "|    2841|            90|\n",
            "|    9110|           107|\n",
            "|    2841|            73|\n",
            "|    1498|            98|\n",
            "|    3125|           125|\n",
            "|    2763|            94|\n",
            "|    6943|           108|\n",
            "|    4616|            88|\n",
            "|    1577|            81|\n",
            "|    1741|            90|\n",
            "|    4390|           202|\n",
            "|  133304|            93|\n",
            "|    2841|            80|\n",
            "|    5265|            90|\n",
            "|    5776|            95|\n",
            "|    2841|            86|\n",
            "|   11419|            97|\n",
            "|  636802|           147|\n",
            "|   53698|            95|\n",
            "|    8828|           104|\n",
            "|    1836|            92|\n",
            "|    2841|           115|\n",
            "+--------+--------------+\n",
            "only showing top 25 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.select(\"labelIndex\", \"prediction\").show(10)"
      ],
      "metadata": {
        "id": "LZUZ_W2FRFuR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51339086-b7c8-4d61-b51a-58600a379226"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+----------+\n",
            "|labelIndex|prediction|\n",
            "+----------+----------+\n",
            "|       1.0|       1.0|\n",
            "|       1.0|       1.0|\n",
            "|       0.0|       0.0|\n",
            "|       1.0|       1.0|\n",
            "|       0.0|       0.0|\n",
            "|       0.0|       1.0|\n",
            "|       0.0|       1.0|\n",
            "|       0.0|       0.0|\n",
            "|       0.0|       1.0|\n",
            "|       0.0|       0.0|\n",
            "+----------+----------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"labelIndex\", predictionCol=\"prediction\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Accuracy = %s\" % (accuracy))\n",
        "print(\"Test Error = %s\" % (1.0 - accuracy))"
      ],
      "metadata": {
        "id": "KZFP1pDxSfEe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75783a5c-4dd8-4a0f-b9f9-15db29d2277f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy = 0.6866145701317019\n",
            "Test Error = 0.3133854298682981\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_val = assembler.transform(df_val)\n",
        "df_test = assembler.transform(df_test)"
      ],
      "metadata": {
        "id": "XoYaASOatWZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## VAL and TEST set\n",
        "print(df_val.count())\n",
        "print(df_test.count())\n",
        "valpredictions = rfModel.transform(df_val)\n",
        "testpredictions = rfModel.transform(df_test)\n",
        "\n",
        "vallabels = valpredictions.select('prediction')\n",
        "testlabels = testpredictions.select('prediction')\n",
        "vallabels.show(40)"
      ],
      "metadata": {
        "id": "jaU15NxGSfGi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f198f6e1-3f16-4205-d6cb-a956d9e74b27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "955\n",
            "1086\n",
            "+----------+\n",
            "|prediction|\n",
            "+----------+\n",
            "|       0.0|\n",
            "|       1.0|\n",
            "|       0.0|\n",
            "|       0.0|\n",
            "|       0.0|\n",
            "|       0.0|\n",
            "|       0.0|\n",
            "|       1.0|\n",
            "|       0.0|\n",
            "|       0.0|\n",
            "|       1.0|\n",
            "|       1.0|\n",
            "|       1.0|\n",
            "|       0.0|\n",
            "|       1.0|\n",
            "|       1.0|\n",
            "|       1.0|\n",
            "|       1.0|\n",
            "|       1.0|\n",
            "|       1.0|\n",
            "|       1.0|\n",
            "|       1.0|\n",
            "|       0.0|\n",
            "|       0.0|\n",
            "|       0.0|\n",
            "|       1.0|\n",
            "|       0.0|\n",
            "|       0.0|\n",
            "|       0.0|\n",
            "|       1.0|\n",
            "|       1.0|\n",
            "|       1.0|\n",
            "|       0.0|\n",
            "|       0.0|\n",
            "|       1.0|\n",
            "|       1.0|\n",
            "|       0.0|\n",
            "|       0.0|\n",
            "|       0.0|\n",
            "|       1.0|\n",
            "+----------+\n",
            "only showing top 40 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "values = {1:False, 0:True}\n",
        "# vallabels = vallabels.replace(values, subset=['prediction'])\n",
        "# testlabels = testlabels.replace(values, subset=['prediction'])\n",
        "vallabels.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5SYShEJ6BVVo",
        "outputId": "4c9ca5b3-a4e5-41f4-db08-c427b5a93b3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|prediction|\n",
            "+----------+\n",
            "|       1.0|\n",
            "|       0.0|\n",
            "|       1.0|\n",
            "|       1.0|\n",
            "|       1.0|\n",
            "|       1.0|\n",
            "|       1.0|\n",
            "|       0.0|\n",
            "|       1.0|\n",
            "|       1.0|\n",
            "|       0.0|\n",
            "|       0.0|\n",
            "|       0.0|\n",
            "|       1.0|\n",
            "|       0.0|\n",
            "|       0.0|\n",
            "|       0.0|\n",
            "|       0.0|\n",
            "|       0.0|\n",
            "|       0.0|\n",
            "+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.types import BooleanType\n",
        "\n",
        "# Convert predictions to boolean\n",
        "vallabels = vallabels.withColumn(\"prediction\", vallabels.prediction.cast(BooleanType())).withColumn('prediction',initcap(col('prediction')))\n",
        "testlabels = testlabels.withColumn(\"prediction\", testlabels.prediction.cast(BooleanType())).withColumn('prediction',initcap(col('prediction')))\n",
        "vallabels.show()"
      ],
      "metadata": {
        "id": "VKRiJ_A_zE39",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec3c2f95-ad57-4db4-f349-0ac0e9c86da8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+\n",
            "|prediction|\n",
            "+----------+\n",
            "|      True|\n",
            "|     False|\n",
            "|      True|\n",
            "|      True|\n",
            "|      True|\n",
            "|      True|\n",
            "|      True|\n",
            "|     False|\n",
            "|      True|\n",
            "|      True|\n",
            "|     False|\n",
            "|     False|\n",
            "|     False|\n",
            "|      True|\n",
            "|     False|\n",
            "|     False|\n",
            "|     False|\n",
            "|     False|\n",
            "|     False|\n",
            "|     False|\n",
            "+----------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "vallabels.write.mode('overwrite').csv('validation123.csv')\n",
        "files.download('validation123.csv')"
      ],
      "metadata": {
        "id": "vP4b6VhESfKq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1a81a70a-1a3e-4898-9b33-29db594edcaf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ef47fe4b-d77d-4523-8950-e5ae92834d56\", \"validation123.csv\", 4096)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testlabels.write.mode('overwrite').csv('test123.csv')\n",
        "files.download('test123.csv')"
      ],
      "metadata": {
        "id": "plHmfSbFSfIq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e893416-b424-41b2-e7b5-baa7a496ebcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_e94fc885-1aae-4b9e-bc7a-486f0296fda1\", \"test123.csv\", 4096)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## VAL and TEST set DONE"
      ],
      "metadata": {
        "id": "GhIK8mXdwIpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0Oa5-a_OtezY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LgKEh04dtemP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Convert label column to numeric type\n",
        "training_data = train.withColumn(\"label\", col(\"label\").cast(\"double\"))\n",
        "\n",
        "# Split training data into train and test sets\n",
        "train_data, test_data = training_data.randomSplit([0.7, 0.3], seed=42)\n",
        "\n",
        "# Define the logistic regression model\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "lr = LogisticRegression(featuresCol='numVotes', labelCol='label', maxIter=10)\n",
        "\n",
        "# Define the parameter grid for tuning\n",
        "from pyspark.ml.tuning import ParamGridBuilder\n",
        "param_grid = ParamGridBuilder() \\\n",
        "    .addGrid(lr.regParam, [0.1, 0.01]) \\\n",
        "    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]) \\\n",
        "    .build()\n",
        "\n",
        "# Define the evaluator\n",
        "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
        "evaluator = BinaryClassificationEvaluator(labelCol='label')\n",
        "\n",
        "# Define the cross-validator\n",
        "from pyspark.ml.tuning import TrainValidationSplit\n",
        "tvs = TrainValidationSplit(estimator=lr,\n",
        "                           estimatorParamMaps=param_grid,\n",
        "                           evaluator=evaluator,\n",
        "                           trainRatio=0.8,\n",
        "                           seed=42)\n",
        "\n",
        "# Fit the model to the training data\n",
        "lr_model = tvs.fit(train_data)\n",
        "\n",
        "# Make predictions on the test data\n",
        "lr_predictions = lr_model.transform(test_data)\n",
        "\n",
        "# Evaluate the model performance on the test data\n",
        "test_auc = evaluator.evaluate(lr_predictions)\n",
        "print('Test AUC:', test_auc)\n"
      ],
      "metadata": {
        "id": "gdKgEfDfMNxo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all = df_all.drop('tconst', 'primaryTitle', 'originalTitle', 'startYear', 'endYear')\n"
      ],
      "metadata": {
        "id": "Cvz-pnei9_J1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "\n",
        "# Convert columns to double data type\n",
        "df_all = df_all.select([df_all[col].cast('double').alias(col) for col in df_all.columns])\n",
        "df_val = df_val.select([df_val[col].cast('double').alias(col) for col in df_val.columns])\n",
        "df_test = df_test.select([df_test[col].cast('double').alias(col) for col in df_test.columns])\n",
        "\n",
        "# Split the features and target variables for the training set\n",
        "feature_cols = [col for col in df_all.columns if col != 'label']\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
        "df_all = assembler.transform(df_all).select('features', 'label')\n",
        "df_val = assembler.transform(df_val).select('features')\n",
        "df_test = assembler.transform(df_test).select('features')\n",
        "\n",
        "rf = RandomForestClassifier()\n",
        "print(\"Number of rows in df_all:\", df_all.count())\n",
        "rf_model = rf.fit(df_all)\n",
        "\n",
        "# Fit the model on the training data\n",
        "rf_model = rf.fit(df_all)\n",
        "\n",
        "# Predict on the validation set\n",
        "y_val_pred = rf_model.transform(df_val)\n",
        "\n",
        "# Evaluate the model using the MulticlassClassificationEvaluator\n",
        "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"accuracy\")\n",
        "val_accuracy = evaluator.evaluate(y_val_pred)\n",
        "print(\"Validation accuracy:\", val_accuracy)\n"
      ],
      "metadata": {
        "id": "-689rwO-m2EY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import count, isnan, when, col\n",
        "\n",
        "# count the number of non-null rows in each column\n",
        "df_all.select([count(when(isnan(c) | col(c).isNull(), c)).alias(c) for c in df_all.columns]).show()\n",
        "\n",
        "# check if the DataFrame is empty\n",
        "if df_all.rdd.isEmpty():\n",
        "    print(\"DataFrame is empty!\")\n",
        "else:\n",
        "    print(\"DataFrame is not empty.\")\n"
      ],
      "metadata": {
        "id": "arzpWmiIpctS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_all.printSchema()\n"
      ],
      "metadata": {
        "id": "ua3A5tsmqWXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_drop = [\"primaryTitle\", \"originalTitle\", \"startYear\", \"endYear\", \"runtimeMinutes\"]\n",
        "df_all = df_all.drop(*columns_to_drop)\n",
        "df_val = df_val.drop(*columns_to_drop)\n",
        "df_test = df_test.drop(*columns_to_drop)\n"
      ],
      "metadata": {
        "id": "Ri6qjX3tceRs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import col\n",
        "\n",
        "# Cast the label column to a numeric type\n",
        "df_all = df_all.withColumn(\"label\", col(\"label\").cast(\"double\"))\n"
      ],
      "metadata": {
        "id": "nw9DqU5ZjHsL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the existing 'features' column if it exists\n",
        "# df_all = df_all.na.drop()\n",
        "\n",
        "\n",
        "if 'features' in df_all.columns:\n",
        "    df_all = df_all.drop('features')\n",
        "\n",
        "# Combine the feature columns into a single vector column\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
        "df_all = assembler.transform(df_all)\n",
        "\n",
        "# Train the logistic regression model on the training dataset\n",
        "lr = LogisticRegression(featuresCol='features', labelCol='label')\n",
        "lr_model = lr.fit(df_all)\n"
      ],
      "metadata": {
        "id": "Iiyrt2ipirnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "# Train the Random Forest model on the training dataset\n",
        "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=10)\n",
        "rf_model = rf.fit(train)\n",
        "\n",
        "# Make predictions on the validation dataset\n",
        "predictions = rf_model.transform(validation)\n",
        "\n",
        "# Evaluate the model's accuracy on the validation dataset\n",
        "evaluator = MulticlassClassificationEvaluator(predictionCol=\"prediction\", labelCol=\"label\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(\"Validation Accuracy = {:.2f}%\".format(accuracy*100))\n"
      ],
      "metadata": {
        "id": "xIRP8yQ9iuRx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L1R3-VCe0sft"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuClass": "premium"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}